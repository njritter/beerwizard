---
title: "Beer Advocate Beer Info Scraper"
author: "Neil Ritter"
date: "7/14/2017"
output: html_document
---

```{r}

library(rvest)

```

## Step 1: Get BeerAdvocate top 250 beer profile URLs 

Note - used SelectorGadget Chrome extension by Andrew Cantino and Kyle Maxwell to find appropriate CSS selectors. 

```{r}
# Read in BA page with top 250 beers on it
top <- read_html("https://www.beeradvocate.com/lists/top/")

```

```{r}
# Get all beer links in top

# find all links on page
all_links <- html_attr(html_nodes(top, "a"), "href")

# this gets all brewery links and beer links
brew_beer_links <- all_links[grep("/beer/profile/", all_links)]

# beer and brewery links happen to alternate and beer links are odd
beer_links <- brew_beer_links[seq(1,500,2)]

```


## Step 2: Read in pages and comments for each beer and blat to text files

The beer profile page contains a maximum of 25 comments. Which comments appear are reflected in the URL of the page, e.g. 

https://www.beeradvocate.com/beer/profile/17981/110635/?view=beer&sort=&start=50

you will see ratings 50 through 75. This lets us iterate through pages via the URL to get all the ratings/comments (only some of the ratings actually have comments).

```{r}
# Helper function to get number of ratings for a beer
get_num_ratings <- function(beer_link){
  
  # read in beer page
  beer <- read_html(paste("https://www.beeradvocate.com", beer_link, sep = ""))
  
  # get number of user ratings
  num_beer_ratings <- html_nodes(beer, "br+ .ba-ratings")
  
  # get rid of commas in character representation of number and then convert to numeric
  return(num_beer_ratings <- as.numeric(gsub(",","",html_text(num_beer_ratings))))
  
}
```

```{r}
# Helper function to read in all ratings for a beer

get_beer_ratings <- function(beer_link) {
  
  # get number of pages to iterate through
  num_pages <- floor(get_num_ratings(beer_link) / 25)
  
  # store each page for beer in list ... will all be same except for ratings
  beer_ratings <- list()
  
  for(page in 1:num_pages){
    
    index <- page * 25 # index added at end of URL to iterate through ratings
    beer_page <- read_html(paste("https://www.beeradvocate.com", 
                                        beer_link, "?view=beer&sort=&start=", 
                                        index, sep = ""))
    ratings <- html_nodes(beer_page, "#rating_fullview_content_2")
    beer_ratings <- c(beer_ratings, ratings)
  }
  
  return(beer_ratings)
  
}
```

```{r}
# Helper function to blat beer ratings into text file
save_ratings <- function(beer_ratings, path){
  
  # not really sure why I have to do this to get at text in beer reviews
  text <- list()
  for(i in 1:length(beer_ratings)){text <- c(text, html_text(beer_ratings[[i]]))}
  
  # Write all beer ratings to text file
  fileConn <- file(path)
  writeLines(as.character(text),fileConn)
  close(fileConn)
}

```

```{r}
# Read in all ratings for each beer and save to text files.
for(i in 1:length(beer_links)){
  
  beer_ratings <- get_beer_ratings(beer_links[i])
  path <- paste("/Users/Drazi/beerwizard/corpra/", "beer_", i, sep = "")
  save_ratings(beer_ratings, path)
  
}


```

```{r}
# Get beer profile page for each beer
beer_profiles = list()

for(i in 1:length(beer_links)){
  
  # read in beer page
  beer_profile <- read_html(paste("https://www.beeradvocate.com", 
                                  beer_links[i], sep = ""))
  
  beer_profiles[[i]] <- beer_profile
  
}

```

```{r}

for(i in 1:length(beer_profiles)){
  
  path <- paste("/Users/Drazi/beerwizard/data/profiles/profile_", i, sep = "" )
  write_xml(beer_profiles[[i]], file = path)
  
  
}

```


